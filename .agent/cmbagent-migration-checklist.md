# CMBAgent è¿ç§»æ¸…å•

æœ¬æ–‡æ¡£åˆ—å‡ºäº† `aiscientist` é¡¹ç›®ä¸­æ‰€æœ‰ä½¿ç”¨ `cmbagent` çš„ä½ç½®ï¼Œä»¥ä¾¿é€ä¸ªè€ƒè™‘æ›¿æ¢ä¸º `planning_and_control_simple` æ–¹æ³•ã€‚

---

## ğŸ“ è°ƒç”¨ç‚¹æ€»è§ˆ

| #   | æ–‡ä»¶             | è¡Œå· | æ–¹æ³•                                     | ä¼˜å…ˆçº§ |
| --- | ---------------- | ---- | ---------------------------------------- | ------ |
| 1   | `idea.py`        | 61   | `planning_and_control_context_carryover` | ğŸ”´ é«˜  |
| 2   | `method.py`      | 49   | `planning_and_control_context_carryover` | ğŸ”´ é«˜  |
| 3   | `experiment.py`  | 82   | `planning_and_control_context_carryover` | ğŸ”´ é«˜  |
| 4   | `aiscientist.py` | 258  | `preprocess_task`                        | ğŸŸ¡ ä¸­  |
| 5   | `aiscientist.py` | 804  | `get_keywords`                           | ğŸŸ¢ ä½  |
| 6   | `paper_node.py`  | 39   | `get_keywords`                           | ğŸŸ¢ ä½  |

---

## ğŸ”´ è°ƒç”¨ç‚¹ 1: Idea Generation (idea.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/idea.py` - ç¬¬ 61-73 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

```python
def develop_idea(self, data_description: str) -> str:
    """
    Develops an idea based on the data description.

    Args:
        data_description: description of the data and tools to be used.
    """

    results = cmbagent.planning_and_control_context_carryover(data_description,
                          n_plan_reviews = 1,
                          max_plan_steps = 6,
                          idea_maker_model = self.idea_maker_model,
                          idea_hater_model = self.idea_hater_model,
                          plan_instructions=self.planner_append_instructions,
                          planner_model=self.planner_model,
                          plan_reviewer_model=self.plan_reviewer_model,
                          work_dir = self.idea_dir,
                          api_keys = self.api_keys,
                          default_llm_model = self.orchestration_model,
                          default_formatter_model = self.formatter_model
                         )

    chat_history = results['chat_history']

    try:
        task_result = get_task_result(chat_history,'idea_maker_nest')
    except Exception as e:
        raise e

    pattern = r'\*\*Ideas\*\*\s*\n- Idea 1:'
    replacement = "Project Idea:"
    task_result = re.sub(pattern, replacement, task_result)

    return task_result
```

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- `idea_maker_model` - åˆ›æ„ç”Ÿæˆå™¨æ¨¡å‹
- `idea_hater_model` - åˆ›æ„æ‰¹è¯„è€…æ¨¡å‹
- `planner_model` - è§„åˆ’å™¨æ¨¡å‹
- `plan_reviewer_model` - è§„åˆ’å®¡æŸ¥è€…æ¨¡å‹
- `default_llm_model` (orchestration_model) - é»˜è®¤ç¼–æ’æ¨¡å‹
- `default_formatter_model` (formatter_model) - æ ¼å¼åŒ–æ¨¡å‹

**æ€»è®¡: 6 ä¸ªä¸åŒçš„æ¨¡å‹å‚æ•°**

### ğŸ’¡ æ›¿æ¢å»ºè®®

```python
def develop_idea(self, data_description: str) -> str:
    """
    Develops an idea based on the data description.

    Args:
        data_description: description of the data and tools to be used.
    """

    results = cmbagent.planning_and_control_simple(
        data_description,
        model = self.unified_model,  # ç»Ÿä¸€æ¨¡å‹
        api_key = self.api_keys.get_key(self.unified_model),
        base_url = self.api_keys.get_base_url(self.unified_model),  # å¦‚æœéœ€è¦
        n_plan_reviews = 1,
        max_plan_steps = 6,
        plan_instructions = self.planner_append_instructions,
        work_dir = self.idea_dir,
        skip_rag_agents = True,  # è·³è¿‡ RAG agents
    )

    chat_history = results['chat_history']

    try:
        task_result = get_task_result(chat_history,'idea_maker_nest')
    except Exception as e:
        raise e

    pattern = r'\*\*Ideas\*\*\s*\n- Idea 1:'
    replacement = "Project Idea:"
    task_result = re.sub(pattern, replacement, task_result)

    return task_result
```

### âš ï¸ æ³¨æ„äº‹é¡¹

- éœ€è¦ä¿®æ”¹ `Idea.__init__()` æ¥å— `unified_model` å‚æ•°
- ç¡®è®¤ `get_task_result` ä»ç„¶èƒ½æ‰¾åˆ° `'idea_maker_nest'` èŠ‚ç‚¹
- æµ‹è¯•ç»“æœè´¨é‡æ˜¯å¦ä¸å¤šæ¨¡å‹ç‰ˆæœ¬ç›¸å½“

### âœ… è¿ç§»æ­¥éª¤

- [ ] ä¿®æ”¹ `Idea.__init__()` ç­¾å
- [ ] æ›´æ–° `develop_idea()` æ–¹æ³•
- [ ] æµ‹è¯• idea generation åŠŸèƒ½
- [ ] å¯¹æ¯”å¤šæ¨¡å‹å’Œå•æ¨¡å‹ç»“æœè´¨é‡
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸ”´ è°ƒç”¨ç‚¹ 2: Method Generation (method.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/method.py` - ç¬¬ 49-62 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

````python
def develop_method(self, data_description: str) -> str:
    """
    Develops the methods based on the data description.

    Args:
        data_description: description of the data and tools to be used.
    """

    results = cmbagent.planning_and_control_context_carryover(data_description,
                          n_plan_reviews = 1,
                          max_n_attempts = 4,
                          max_plan_steps = 4,
                          researcher_model = self.researcher_model,
                          planner_model = self.planner_model,
                          plan_reviewer_model = self.plan_reviewer_model,
                          plan_instructions = self.planner_append_instructions,
                          researcher_instructions = self.researcher_append_instructions,
                          work_dir = self.method_dir,
                          api_keys = self.api_keys,
                          default_llm_model = self.orchestration_model,
                          default_formatter_model = self.formatter_model
                         )

    chat_history = results['chat_history']

    try:
        task_result = get_task_result(chat_history,'researcher_response_formatter')
    except Exception as e:
        raise e

    MD_CODE_BLOCK_PATTERN = r"```[ \t]*(?:markdown)[ \t]*\r?\n(.*)\r?\n[ \t]*```"
    extracted_methodology = re.findall(MD_CODE_BLOCK_PATTERN, task_result, flags=re.DOTALL)[0]
    clean_methodology = re.sub(r'^<!--.*?-->\s*\n', '', extracted_methodology)
    return clean_methodology
````

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- `researcher_model` - ç ”ç©¶è€…æ¨¡å‹
- `planner_model` - è§„åˆ’å™¨æ¨¡å‹
- `plan_reviewer_model` - è§„åˆ’å®¡æŸ¥è€…æ¨¡å‹
- `default_llm_model` (orchestration_model) - é»˜è®¤ç¼–æ’æ¨¡å‹
- `default_formatter_model` (formatter_model) - æ ¼å¼åŒ–æ¨¡å‹

**æ€»è®¡: 5 ä¸ªä¸åŒçš„æ¨¡å‹å‚æ•°**

### ğŸ’¡ æ›¿æ¢å»ºè®®

````python
def develop_method(self, data_description: str) -> str:
    """
    Develops the methods based on the data description.

    Args:
        data_description: description of the data and tools to be used.
    """

    results = cmbagent.planning_and_control_simple(
        data_description,
        model = self.unified_model,  # ç»Ÿä¸€æ¨¡å‹
        api_key = self.api_keys.get_key(self.unified_model),
        base_url = self.api_keys.get_base_url(self.unified_model),  # å¦‚æœéœ€è¦
        n_plan_reviews = 1,
        max_n_attempts = 4,
        max_plan_steps = 4,
        plan_instructions = self.planner_append_instructions,
        researcher_instructions = self.researcher_append_instructions,
        work_dir = self.method_dir,
        skip_rag_agents = True,
    )

    chat_history = results['chat_history']

    try:
        task_result = get_task_result(chat_history,'researcher_response_formatter')
    except Exception as e:
        raise e

    MD_CODE_BLOCK_PATTERN = r"```[ \t]*(?:markdown)[ \t]*\r?\n(.*)\r?\n[ \t]*```"
    extracted_methodology = re.findall(MD_CODE_BLOCK_PATTERN, task_result, flags=re.DOTALL)[0]
    clean_methodology = re.sub(r'^<!--.*?-->\s*\n', '', extracted_methodology)
    return clean_methodology
````

### âš ï¸ æ³¨æ„äº‹é¡¹

- éœ€è¦ä¿®æ”¹ `Method.__init__()` æ¥å— `unified_model` å‚æ•°
- ç¡®è®¤ `get_task_result` ä»ç„¶èƒ½æ‰¾åˆ° `'researcher_response_formatter'` èŠ‚ç‚¹
- ä¿ç•™ `researcher_instructions` å‚æ•°ä¼ é€’

### âœ… è¿ç§»æ­¥éª¤

- [ ] ä¿®æ”¹ `Method.__init__()` ç­¾å
- [ ] æ›´æ–° `develop_method()` æ–¹æ³•
- [ ] æµ‹è¯• method generation åŠŸèƒ½
- [ ] å¯¹æ¯”å¤šæ¨¡å‹å’Œå•æ¨¡å‹ç»“æœè´¨é‡
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸ”´ è°ƒç”¨ç‚¹ 3: Experiment Execution (experiment.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/experiment.py` - ç¬¬ 82-100 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

````python
def run_experiment(self, data_description: str, **kwargs):
    """
    Run the experiment.
    TODO: improve docstring
    """

    print(f"Engineer model: {self.engineer_model}")
    print(f"Researcher model: {self.researcher_model}")
    print(f"Planner model: {self.planner_model}")
    print(f"Plan reviewer model: {self.plan_reviewer_model}")
    print(f"Max n attempts: {self.max_n_attempts}")
    print(f"Max n steps: {self.max_n_steps}")
    print(f"Restart at step: {self.restart_at_step}")
    print(f"Hardware constraints: {self.hardware_constraints}")

    results = cmbagent.planning_and_control_context_carryover(data_description,
                        n_plan_reviews = 1,
                        max_n_attempts = self.max_n_attempts,
                        max_plan_steps = self.max_n_steps,
                        max_rounds_control = 500,
                        engineer_model = self.engineer_model,
                        researcher_model = self.researcher_model,
                        planner_model = self.planner_model,
                        plan_reviewer_model = self.plan_reviewer_model,
                        plan_instructions=self.planner_append_instructions,
                        researcher_instructions=self.researcher_append_instructions,
                        engineer_instructions=self.engineer_append_instructions,
                        work_dir = self.experiment_dir,
                        api_keys = self.api_keys,
                        restart_at_step = self.restart_at_step,
                        hardware_constraints = self.hardware_constraints,
                        default_llm_model = self.orchestration_model,
                        default_formatter_model = self.formatter_model
                        )
    chat_history = results['chat_history']
    final_context = results['final_context']

    try:
        task_result = get_task_result(chat_history,'researcher_response_formatter')
    except Exception as e:
        raise e

    MD_CODE_BLOCK_PATTERN = r"```[ \t]*(?:markdown)[ \t]*\r?\n(.*)\r?\n[ \t]*```"
    extracted_results = re.findall(MD_CODE_BLOCK_PATTERN, task_result, flags=re.DOTALL)[0]
    clean_results = re.sub(r'^<!--.*?-->\s*\n', '', extracted_results)
    self.results = clean_results
    self.plot_paths = final_context['displayed_images']

    return None
````

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- `engineer_model` - å·¥ç¨‹å¸ˆæ¨¡å‹
- `researcher_model` - ç ”ç©¶è€…æ¨¡å‹
- `planner_model` - è§„åˆ’å™¨æ¨¡å‹
- `plan_reviewer_model` - è§„åˆ’å®¡æŸ¥è€…æ¨¡å‹
- `default_llm_model` (orchestration_model) - é»˜è®¤ç¼–æ’æ¨¡å‹
- `default_formatter_model` (formatter_model) - æ ¼å¼åŒ–æ¨¡å‹

**æ€»è®¡: 6 ä¸ªä¸åŒçš„æ¨¡å‹å‚æ•°**

### ğŸ’¡ æ›¿æ¢å»ºè®®

````python
def run_experiment(self, data_description: str, **kwargs):
    """
    Run the experiment.
    TODO: improve docstring
    """

    print(f"Unified model: {self.unified_model}")
    print(f"Max n attempts: {self.max_n_attempts}")
    print(f"Max n steps: {self.max_n_steps}")
    print(f"Restart at step: {self.restart_at_step}")
    print(f"Hardware constraints: {self.hardware_constraints}")

    results = cmbagent.planning_and_control_simple(
        data_description,
        model = self.unified_model,  # ç»Ÿä¸€æ¨¡å‹
        api_key = self.api_keys.get_key(self.unified_model),
        base_url = self.api_keys.get_base_url(self.unified_model),  # å¦‚æœéœ€è¦
        n_plan_reviews = 1,
        max_n_attempts = self.max_n_attempts,
        max_plan_steps = self.max_n_steps,
        max_rounds_control = 500,
        plan_instructions = self.planner_append_instructions,
        researcher_instructions = self.researcher_append_instructions,
        engineer_instructions = self.engineer_append_instructions,
        work_dir = self.experiment_dir,
        restart_at_step = self.restart_at_step,
        hardware_constraints = self.hardware_constraints,
        skip_rag_agents = True,
    )
    chat_history = results['chat_history']
    final_context = results['final_context']

    try:
        task_result = get_task_result(chat_history,'researcher_response_formatter')
    except Exception as e:
        raise e

    MD_CODE_BLOCK_PATTERN = r"```[ \t]*(?:markdown)[ \t]*\r?\n(.*)\r?\n[ \t]*```"
    extracted_results = re.findall(MD_CODE_BLOCK_PATTERN, task_result, flags=re.DOTALL)[0]
    clean_results = re.sub(r'^<!--.*?-->\s*\n', '', extracted_results)
    self.results = clean_results
    self.plot_paths = final_context['displayed_images']

    return None
````

### âš ï¸ æ³¨æ„äº‹é¡¹

- éœ€è¦ä¿®æ”¹ `Experiment.__init__()` æ¥å— `unified_model` å‚æ•°
- è¿™æ˜¯æœ€å¤æ‚çš„è°ƒç”¨ï¼Œéœ€è¦ä¿ç•™ `engineer_instructions` å’Œ `researcher_instructions`
- ç¡®è®¤ `final_context['displayed_images']` ä»ç„¶å¯ç”¨
- **å…³é”®**: å®éªŒæ‰§è¡Œæ¶‰åŠä»£ç ç”Ÿæˆå’Œæ‰§è¡Œï¼Œéœ€è¦é‡ç‚¹æµ‹è¯•

### âœ… è¿ç§»æ­¥éª¤

- [ ] ä¿®æ”¹ `Experiment.__init__()` ç­¾å
- [ ] æ›´æ–° `run_experiment()` æ–¹æ³•
- [ ] æµ‹è¯•å®Œæ•´çš„å®éªŒæµç¨‹
- [ ] éªŒè¯ä»£ç ç”Ÿæˆå’Œæ‰§è¡ŒåŠŸèƒ½
- [ ] å¯¹æ¯”å¤šæ¨¡å‹å’Œå•æ¨¡å‹ç»“æœè´¨é‡
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸŸ¡ è°ƒç”¨ç‚¹ 4: Data Description Enhancement (aiscientist.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/aiscientist.py` - ç¬¬ 258-262 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

```python
def enhance_data_description(self,
                             summarizer_model: str,
                             summarizer_response_formatter_model: str) -> None:
    """
    Enhance the data description using the preprocess_task from cmbagent.

    Args:
        summarizer_model: LLM to be used for summarization.
        summarizer_response_formatter_model: LLM to be used for formatting the summarization response.
    """

    # Check if data description exists
    if not hasattr(self.research, 'data_description') or not self.research.data_description:
        # Try to load from file if it exists
        try:
            with open(os.path.join(self.project_dir, INPUT_FILES, DESCRIPTION_FILE), 'r') as f:
                self.research.data_description = f.read()
        except FileNotFoundError:
            raise ValueError("No data description found. Please set a data description first before enhancing it.")

    # Get the enhanced text from preprocess_task
    enhanced_text = preprocess_task(self.research.data_description,
                                    work_dir = self.project_dir,
                                    summarizer_model = summarizer_model,
                                    summarizer_response_formatter_model = summarizer_response_formatter_model
                                    )

    # ... (åç»­å¤„ç†ä»£ç )
```

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- `summarizer_model` - æ‘˜è¦ç”Ÿæˆæ¨¡å‹
- `summarizer_response_formatter_model` - æ ¼å¼åŒ–æ¨¡å‹

**æ€»è®¡: 2 ä¸ªä¸åŒçš„æ¨¡å‹å‚æ•°**

### ğŸ’¡ æ›¿æ¢å»ºè®®

**é€‰é¡¹ A: å¦‚æœ cmbagent æä¾›äº† `preprocess_task_simple`**

```python
def enhance_data_description(self,
                             model: str = None) -> None:
    """
    Enhance the data description using the preprocess_task from cmbagent.

    Args:
        model: LLM to be used for summarization (optional, uses unified_model if not provided).
    """

    # Check if data description exists
    if not hasattr(self.research, 'data_description') or not self.research.data_description:
        try:
            with open(os.path.join(self.project_dir, INPUT_FILES, DESCRIPTION_FILE), 'r') as f:
                self.research.data_description = f.read()
        except FileNotFoundError:
            raise ValueError("No data description found. Please set a data description first before enhancing it.")

    # Use unified model if not specified
    model = model or self.unified_model

    # Get the enhanced text from preprocess_task_simple
    enhanced_text = preprocess_task_simple(
        self.research.data_description,
        work_dir = self.project_dir,
        model = model,
        api_key = self.keys.get_key(model),
        base_url = self.keys.get_base_url(model),
    )

    # ... (åç»­å¤„ç†ä»£ç )
```

**é€‰é¡¹ B: ä¿æŒä¸å˜ï¼ˆä¼˜å…ˆçº§è¾ƒä½ï¼‰**

- `preprocess_task` åŠŸèƒ½ç›¸å¯¹ç‹¬ç«‹ï¼Œå¯ä»¥æš‚æ—¶ä¿ç•™åŸæœ‰çš„åŒæ¨¡å‹æ¨¡å¼
- ç­‰å¾… cmbagent æä¾›ç®€åŒ–ç‰ˆæœ¬åå†è¿ç§»

### âš ï¸ æ³¨æ„äº‹é¡¹

- éœ€è¦ç¡®è®¤ cmbagent æ˜¯å¦æä¾›äº† `preprocess_task_simple` æ–¹æ³•
- å¦‚æœæ²¡æœ‰ï¼Œå¯ä»¥è€ƒè™‘åœ¨æ­¤é˜¶æ®µè·³è¿‡æ­¤è°ƒç”¨ç‚¹
- è¿™æ˜¯é¢„å¤„ç†æ­¥éª¤ï¼Œå½±å“ç›¸å¯¹è¾ƒå°

### âœ… è¿ç§»æ­¥éª¤

- [ ] ç¡®è®¤ cmbagent æ˜¯å¦æœ‰ `preprocess_task_simple`
- [ ] å¦‚æœæœ‰ï¼Œä¿®æ”¹ `enhance_data_description()` æ–¹æ³•
- [ ] å¦‚æœæ²¡æœ‰ï¼Œæš‚æ—¶è·³è¿‡ï¼Œä¿ç•™åŸæœ‰å®ç°
- [ ] æµ‹è¯•æ•°æ®æè¿°å¢å¼ºåŠŸèƒ½
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸŸ¢ è°ƒç”¨ç‚¹ 5: Get Keywords (aiscientist.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/aiscientist.py` - ç¬¬ 804 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

```python
def get_keywords(self, input_text: str, n_keywords: int = 5, kw_type: str = 'unesco') -> None:
    """
    Get keywords from input text using cmbagent.

    Args:
        input_text (str): Text to extract keywords from
        n_keywords (int, optional): Number of keywords to extract. Defaults to 5.
        kw_type (str, optional): Type of keywords to extract. Defaults to 'unesco'.

    Returns:
        dict: Dictionary mapping keywords to their URLs
    """

    keywords = cmbagent.get_keywords(input_text, n_keywords = n_keywords, kw_type = kw_type, api_keys = self.keys)
    self.research.keywords = keywords # type: ignore
    print('keywords: ', self.research.keywords)
```

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- `api_keys` - é€šè¿‡ KeyManager ç®¡ç†ï¼Œå†…éƒ¨å¯èƒ½ä½¿ç”¨é»˜è®¤æ¨¡å‹

**æ€»è®¡: éšå¼ä½¿ç”¨ 1 ä¸ªæ¨¡å‹**

### ğŸ’¡ æ›¿æ¢å»ºè®®

**é€‰é¡¹ A: å¦‚æœ cmbagent æä¾›äº† `get_keywords_simple`**

```python
def get_keywords(self, input_text: str, n_keywords: int = 5, kw_type: str = 'unesco', model: str = None) -> None:
    """
    Get keywords from input text using cmbagent.

    Args:
        input_text (str): Text to extract keywords from
        n_keywords (int, optional): Number of keywords to extract. Defaults to 5.
        kw_type (str, optional): Type of keywords to extract. Defaults to 'unesco'.
        model (str, optional): LLM model to use. Defaults to unified_model.

    Returns:
        dict: Dictionary mapping keywords to their URLs
    """

    # Use unified model if not specified
    model = model or self.unified_model

    keywords = cmbagent.get_keywords_simple(
        input_text,
        n_keywords = n_keywords,
        kw_type = kw_type,
        model = model,
        api_key = self.keys.get_key(model),
        base_url = self.keys.get_base_url(model),
    )
    self.research.keywords = keywords # type: ignore
    print('keywords: ', self.research.keywords)
```

**é€‰é¡¹ B: ä¿æŒä¸å˜ï¼ˆå¦‚æœ cmbagent å†…éƒ¨å·²ç»ç®€åŒ–ï¼‰**

- å¦‚æœ `get_keywords` æœ¬èº«å·²ç»åªä½¿ç”¨å•ä¸€æ¨¡å‹ï¼Œå¯ä»¥ä¿æŒä¸å˜
- åªéœ€è¦ç¡®ä¿ä¼ å…¥çš„ `api_keys` åŒ…å«æ­£ç¡®çš„æ¨¡å‹é…ç½®

### âš ï¸ æ³¨æ„äº‹é¡¹

- è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©åŠŸèƒ½ï¼Œä¼˜å…ˆçº§è¾ƒä½
- éœ€è¦ç¡®è®¤ cmbagent æ˜¯å¦æä¾›äº† `get_keywords_simple` æ–¹æ³•
- å¦‚æœåŸæ–¹æ³•å·²ç»å¾ˆç®€å•ï¼Œå¯ä»¥ä¸ä¿®æ”¹

### âœ… è¿ç§»æ­¥éª¤

- [ ] ç¡®è®¤ cmbagent çš„ `get_keywords` æ–¹æ³•ç­¾å
- [ ] ç¡®è®¤æ˜¯å¦éœ€è¦ `get_keywords_simple`
- [ ] å¦‚æœéœ€è¦ï¼Œä¿®æ”¹è°ƒç”¨æ–¹å¼
- [ ] æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸŸ¢ è°ƒç”¨ç‚¹ 6: Keywords in Paper Node (paper_node.py)

### ğŸ“„ æ–‡ä»¶ä½ç½®

`aiscientist/paper_agents/paper_node.py` - ç¬¬ 39 è¡Œ

### ğŸ“‹ å½“å‰å®ç°

```python
if state['paper']['cmbagent_keywords']:
    ################ CMB Agent keywords ###############
    # Extract keywords
    PROMPT = cmbagent_keywords_prompt(state)
    keywords = cmbagent.get_keywords(PROMPT, n_keywords = 8)

    # Extract keys and join them with a comma.
    keywords = ", ".join(keywords.keys())
    ###################################################
```

### ğŸ¯ ä½¿ç”¨çš„æ¨¡å‹å‚æ•°

- éšå¼ä½¿ç”¨å†…éƒ¨é»˜è®¤æ¨¡å‹

**æ€»è®¡: éšå¼ä½¿ç”¨ 1 ä¸ªæ¨¡å‹**

### ğŸ’¡ æ›¿æ¢å»ºè®®

**é€‰é¡¹ A: ä¼ å…¥ç»Ÿä¸€æ¨¡å‹ï¼ˆæ¨èï¼‰**

```python
if state['paper']['cmbagent_keywords']:
    ################ CMB Agent keywords ###############
    # Extract keywords
    PROMPT = cmbagent_keywords_prompt(state)

    # ä» state è·å–ç»Ÿä¸€æ¨¡å‹é…ç½®
    model = state.get('unified_model', 'gpt-4o')  # é»˜è®¤å€¼
    api_key = state['keys'].get_key(model)
    base_url = state['keys'].get_base_url(model)

    keywords = cmbagent.get_keywords_simple(
        PROMPT,
        n_keywords = 8,
        model = model,
        api_key = api_key,
        base_url = base_url,
    )

    # Extract keys and join them with a comma.
    keywords = ", ".join(keywords.keys())
    ###################################################
```

**é€‰é¡¹ B: ä¿®æ”¹ state ç»“æ„**

```python
# åœ¨è°ƒç”¨ paper generation æ—¶ï¼Œç¡®ä¿ state åŒ…å«ç»Ÿä¸€æ¨¡å‹é…ç½®
input_state = {
    "files": {"Folder": self.project_dir},
    "llm": {
        "model": llm.name,
        "temperature": llm.temperature,
        "max_output_tokens": llm.max_output_tokens
    },
    "unified_model": llm.name,  # æ·»åŠ ç»Ÿä¸€æ¨¡å‹é…ç½®
    "paper": {
        "journal": journal,
        "add_citations": add_citations,
        "cmbagent_keywords": cmbagent_keywords
    },
    "keys": self.keys,
    "writer": writer,
}
```

### âš ï¸ æ³¨æ„äº‹é¡¹

- éœ€è¦ä¿®æ”¹ `GraphState` ç±»å‹å®šä¹‰ï¼Œæ·»åŠ  `unified_model` å­—æ®µ
- æˆ–è€…ç›´æ¥ä» `state['llm']['model']` è·å–æ¨¡å‹åç§°
- è¿™æ˜¯è®ºæ–‡ç”Ÿæˆæµç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œéœ€è¦ä¿æŒä¸€è‡´æ€§

### âœ… è¿ç§»æ­¥éª¤

- [ ] ç¡®è®¤ `GraphState` ç±»å‹å®šä¹‰ä½ç½®
- [ ] æ·»åŠ  `unified_model` å­—æ®µåˆ° state
- [ ] ä¿®æ”¹ `keywords_node` å‡½æ•°
- [ ] æµ‹è¯•è®ºæ–‡å…³é”®è¯ç”ŸæˆåŠŸèƒ½
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸ“Š è¿ç§»ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»

### ä¼˜å…ˆçº§é¡ºåº

1. **ğŸ”´ é«˜ä¼˜å…ˆçº§** (æ ¸å¿ƒåŠŸèƒ½)
   - è°ƒç”¨ç‚¹ 1: Idea Generation
   - è°ƒç”¨ç‚¹ 2: Method Generation
   - è°ƒç”¨ç‚¹ 3: Experiment Execution

2. **ğŸŸ¡ ä¸­ä¼˜å…ˆçº§** (è¾…åŠ©åŠŸèƒ½)
   - è°ƒç”¨ç‚¹ 4: Data Description Enhancement

3. **ğŸŸ¢ ä½ä¼˜å…ˆçº§** (å¯é€‰åŠŸèƒ½)
   - è°ƒç”¨ç‚¹ 5: Get Keywords (aiscientist.py)
   - è°ƒç”¨ç‚¹ 6: Keywords in Paper Node

### ä¾èµ–å…³ç³»

```
è°ƒç”¨ç‚¹ 1 (Idea) â†’ è°ƒç”¨ç‚¹ 2 (Method) â†’ è°ƒç”¨ç‚¹ 3 (Experiment) â†’ è°ƒç”¨ç‚¹ 6 (Paper Keywords)
                                                                   â†‘
                                                     è°ƒç”¨ç‚¹ 5 (Get Keywords)
                                                                   â†‘
è°ƒç”¨ç‚¹ 4 (Enhance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å»ºè®®è¿ç§»é¡ºåº

1. å…ˆè¿ç§» **è°ƒç”¨ç‚¹ 1** (Idea)ï¼ŒéªŒè¯åŸºæœ¬åŠŸèƒ½
2. è¿ç§» **è°ƒç”¨ç‚¹ 2** (Method)ï¼Œç¡®ä¿æµç¨‹è¿è´¯
3. è¿ç§» **è°ƒç”¨ç‚¹ 3** (Experiment)ï¼Œå®Œæˆæ ¸å¿ƒåŠŸèƒ½è¿ç§»
4. è¿ç§» **è°ƒç”¨ç‚¹ 6** (Paper Keywords)ï¼Œä¸è°ƒç”¨ç‚¹ 3 ä¸€èµ·æµ‹è¯•
5. è¿ç§» **è°ƒç”¨ç‚¹ 5** (Get Keywords)ï¼Œç¡®ä¿ API ä¸€è‡´æ€§
6. æœ€åè¿ç§» **è°ƒç”¨ç‚¹ 4** (Enhance)ï¼Œå¦‚æœ cmbagent æä¾›äº†ç®€åŒ–ç‰ˆæœ¬

---

## ğŸ› ï¸ æ‰€éœ€çš„ cmbagent æ–¹æ³•

ä¸ºäº†å®Œæˆè¿ç§»ï¼Œéœ€è¦ `cmbagent` æä¾›ä»¥ä¸‹æ–¹æ³•ï¼š

### 1. `planning_and_control_simple` âœ… (å·²æä¾›)

```python
def planning_and_control_simple(
    data_description: str,
    model: str,
    api_key: str | dict,
    base_url: str | None = None,
    n_plan_reviews: int = 1,
    max_plan_steps: int = 6,
    max_n_attempts: int = 10,
    max_rounds_control: int = 500,
    plan_instructions: str | None = None,
    researcher_instructions: str | None = None,
    engineer_instructions: str | None = None,
    work_dir: str | Path,
    restart_at_step: int = -1,
    hardware_constraints: str | None = None,
    skip_rag_agents: bool = True,
    **kwargs
) -> dict
```

### 2. `get_keywords_simple` â“ (éœ€è¦ç¡®è®¤)

```python
def get_keywords_simple(
    prompt: str,
    n_keywords: int = 8,
    model: str = "gpt-4o",
    api_key: str | dict = None,
    base_url: str | None = None,
    kw_type: str = 'aas',
) -> dict
```

### 3. `preprocess_task_simple` â“ (éœ€è¦ç¡®è®¤)

```python
def preprocess_task_simple(
    data_description: str,
    work_dir: str | Path,
    model: str,
    api_key: str | dict,
    base_url: str | None = None,
) -> str
```

---

## ğŸ“ é€šç”¨ä¿®æ”¹æ¨¡å¼

### ç±»æ„é€ å‡½æ•°ä¿®æ”¹æ¨¡å¼

```python
# Before
class SomeClass:
    def __init__(self,
                 model_a: str,
                 model_b: str,
                 model_c: str,
                 ...):
        self.model_a = model_a
        self.model_b = model_b
        self.model_c = model_c

# After
class SomeClass:
    def __init__(self,
                 unified_model: str = "gpt-4o",
                 # ä¿ç•™æ—§å‚æ•°ä»¥å®ç°å‘åå…¼å®¹
                 model_a: str = None,
                 model_b: str = None,
                 model_c: str = None,
                 use_simple_mode: bool = True,
                 ...):
        if use_simple_mode:
            self.unified_model = unified_model
        else:
            # å‘åå…¼å®¹æ¨¡å¼
            self.model_a = model_a or unified_model
            self.model_b = model_b or unified_model
            self.model_c = model_c or unified_model
```

### API è°ƒç”¨ä¿®æ”¹æ¨¡å¼

```python
# Before
results = cmbagent.planning_and_control_context_carryover(
    data_description,
    model_a = self.model_a,
    model_b = self.model_b,
    model_c = self.model_c,
    api_keys = self.api_keys,
    ...
)

# After
results = cmbagent.planning_and_control_simple(
    data_description,
    model = self.unified_model,
    api_key = self.api_keys.get_key(self.unified_model),
    base_url = self.api_keys.get_base_url(self.unified_model),
    skip_rag_agents = True,
    ...
)
```

---

## âœ… è¿ç§»æ£€æŸ¥æ¸…å•

### å‡†å¤‡é˜¶æ®µ

- [ ] é˜…è¯»æœ¬è¿ç§»æ¸…å•
- [ ] ç†è§£ `planning_and_control_simple` çš„æ¥å£å’Œè¡Œä¸º
- [ ] ç¡®è®¤ cmbagent ç‰ˆæœ¬æ›´æ–°åˆ°åŒ…å« `planning_and_control_simple` çš„ç‰ˆæœ¬
- [ ] åˆ›å»ºæµ‹è¯•åˆ†æ”¯è¿›è¡Œè¿ç§»å·¥ä½œ
- [ ] å¤‡ä»½å½“å‰å·¥ä½œä»£ç 

### æ ¸å¿ƒè¿ç§»

- [ ] è¿ç§»è°ƒç”¨ç‚¹ 1: Idea Generation
- [ ] æµ‹è¯• idea generation åŠŸèƒ½
- [ ] è¿ç§»è°ƒç”¨ç‚¹ 2: Method Generation
- [ ] æµ‹è¯• method generation åŠŸèƒ½
- [ ] è¿ç§»è°ƒç”¨ç‚¹ 3: Experiment Execution
- [ ] æµ‹è¯•å®Œæ•´çš„ç ”ç©¶æµç¨‹ (idea â†’ method â†’ experiment)

### è¾…åŠ©åŠŸèƒ½è¿ç§»

- [ ] è¿ç§»è°ƒç”¨ç‚¹ 6: Keywords in Paper Node
- [ ] æµ‹è¯•è®ºæ–‡ç”ŸæˆåŠŸèƒ½
- [ ] è¿ç§»è°ƒç”¨ç‚¹ 5: Get Keywords (aiscientist.py)
- [ ] æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½
- [ ] è¿ç§»è°ƒç”¨ç‚¹ 4: Data Description Enhancement (å¦‚æœå¯ç”¨)

### è´¨é‡ä¿è¯

- [ ] è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•
- [ ] å¯¹æ¯”å•æ¨¡å‹å’Œå¤šæ¨¡å‹ç‰ˆæœ¬çš„è¾“å‡ºè´¨é‡
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] æˆæœ¬åˆ†æ (API è°ƒç”¨æ¬¡æ•°å’Œ tokens ä½¿ç”¨)
- [ ] ä»£ç å®¡æŸ¥

### æ–‡æ¡£å’Œæ¸…ç†

- [ ] æ›´æ–° README.md
- [ ] æ›´æ–° API æ–‡æ¡£
- [ ] æ›´æ–°ç¤ºä¾‹ä»£ç 
- [ ] æ·»åŠ è¿ç§»æŒ‡å—
- [ ] æ¸…ç†å·²å¼ƒç”¨çš„ä»£ç  (å¦‚æœå†³å®šä¸ä¿ç•™å‘åå…¼å®¹)

---

## ğŸ“ˆ é¢„æœŸæ”¶ç›Š

### æˆæœ¬é™ä½

- **å‡å°‘ API è°ƒç”¨**: ä» 6 ä¸ªä¸åŒçš„æ¨¡å‹è°ƒç”¨å‡å°‘åˆ° 1 ä¸ª
- **å‡å°‘ Token ä½¿ç”¨**: é¿å…åœ¨ä¸åŒæ¨¡å‹é—´åˆ‡æ¢çš„é¢å¤–å¼€é”€
- **ä¼°ç®—èŠ‚çœ**: çº¦ 40-60% çš„ API æˆæœ¬ï¼ˆå–å†³äºå…·ä½“ä½¿ç”¨åœºæ™¯ï¼‰

### ä»£ç ç®€åŒ–

- **å‡å°‘å‚æ•°**: æ¯ä¸ªç±»çš„æ„é€ å‡½æ•°å‚æ•°ä» 6-7 ä¸ªå‡å°‘åˆ° 1-2 ä¸ª
- **æ›´æ˜“ç»´æŠ¤**: ç»Ÿä¸€çš„æ¨¡å‹é…ç½®æ›´å®¹æ˜“ç®¡ç†å’Œè°ƒè¯•
- **æ›´å°‘é”™è¯¯**: å‡å°‘é…ç½®é”™è¯¯çš„å¯èƒ½æ€§

### æ€§èƒ½æ”¹è¿›

- **æ›´å¿«æ‰§è¡Œ**: å‡å°‘æ¨¡å‹åˆ‡æ¢å’Œåˆå§‹åŒ–å¼€é”€
- **æ›´ç®€å•çš„é”™è¯¯å¤„ç†**: å•ä¸€æ¨¡å‹çš„é”™è¯¯å¤„ç†æ›´ç›´æ¥

---

## âš ï¸ æ½œåœ¨é£é™©

### åŠŸèƒ½é™çº§é£é™©

- **è´¨é‡å½±å“**: å•ä¸€æ¨¡å‹å¯èƒ½ä¸å¦‚ä¸“é—¨ä¼˜åŒ–çš„å¤šæ¨¡å‹ç»„åˆ
- **ç¼“è§£æªæ–½**:
  - è¿›è¡Œå……åˆ†çš„ A/B æµ‹è¯•
  - ä¿ç•™å‘åå…¼å®¹é€‰é¡¹
  - åœ¨å…³é”®è·¯å¾„ä¸Šä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚ gpt-4oï¼‰

### æŠ€æœ¯å€ºåŠ¡

- **å‘åå…¼å®¹**: å¦‚æœä¿ç•™æ—§ä»£ç ä¼šå¢åŠ ç»´æŠ¤è´Ÿæ‹…
- **ç¼“è§£æªæ–½**:
  - è®¡åˆ’åœ¨ 6 ä¸ªæœˆåå®Œå…¨ç§»é™¤æ—§ä»£ç 
  - æ˜ç¡®æ ‡è®°å¼ƒç”¨çš„å‚æ•°å’Œæ–¹æ³•

### ä¾èµ–é£é™©

- **cmbagent æ›´æ–°**: ä¾èµ–å¤–éƒ¨æ¨¡å—çš„æ–°åŠŸèƒ½
- **ç¼“è§£æªæ–½**:
  - é”å®š cmbagent ç‰ˆæœ¬
  - ä¸ cmbagent å›¢é˜Ÿä¿æŒæ²Ÿé€š
  - ä¸ºå…³é”®åŠŸèƒ½å‡†å¤‡å¤‡ç”¨æ–¹æ¡ˆ

---

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

å¦‚æœåœ¨è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥ cmbagent çš„æ–‡æ¡£å’Œæ›´æ–°æ—¥å¿—
2. å‚è€ƒæœ¬æ¸…å•ä¸­çš„ç¤ºä¾‹ä»£ç 
3. ä¸å›¢é˜Ÿè®¨è®ºç‰¹å®šçš„æŠ€æœ¯ç»†èŠ‚
4. è®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼Œæ›´æ–°æœ¬æ–‡æ¡£

---

**æœ€åæ›´æ–°**: 2026-01-14
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**ä½œè€…**: AI Assistant
